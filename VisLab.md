http://www.cs.umb.edu/~marc/lab/

# Introduction #

In the Visual Attention Lab, we study the attentional mechanisms underlying human vision. We are particularly interested in investigating how attention is controlled for efficient performance of visual tasks. Our main research paradigms are eye-movement recording and computational modeling. The findings resulting from this research are applied to the construction of computer vision systems and human-computer interfaces. More specifically, there are three main areas of research that we focus on:

## Studying Human Eye Movements ##

We use an SR Research EyeLink-II head-mounted system to record eye movements during visual tasks. Eye movements provide insight into attentional processes that form the basis for efficient conscious processing of visual information. In particular, we employ visual search and comparative visual search experiments to investigate the interaction of visual attention, eye movements, and visual working memory to gain a better understanding of the visual system. Besides basic research on the visual system, we also conduct clinical eye-movement research on schizophrenic patients in joint work with the VA Brockton.

## Computational Modeling of Cognitive and Perceptual Processes ##

Our modeling and simulation of processes in the human brain is aimed at two goals: First, we would like to test whether our conclusions from empirical studies are plausible. For this purpose we build a computational model of the assumed processes in the visual system, and then simulate these processes on a computer. A comparison of simulated and actual human behavior (with regard to eye movement patterns, psychometric functions etc.) can identify the strengths and weaknesses of the current model. Second, we investigate whether our models can be used to improve technical systems such as computer vision applications, human-computer interfaces, or image retrieval systems.

## Developing Gaze-Controlled Human-Computer Interfaces ##

Human eye movements are a very fast, effortless, and intuitive way of controlling a computer program. However, not all eye movements are control-related and completely under conscious command, which needs to be considered for the construction of gaze-controlled interfaces. In the Visual Attention Lab, we build gaze-controlled interfaces for physically challenged users as well as multimodal interfaces for specific control tasks performed by healthy operators. In order to improve gaze-controlled human-computer interaction, we study eye-hand timing issues such as the eye-hand span that affects the use of multimodal interfaces.